# ğŸ§  Transformer-Based Text Classification: Hate, Sentiment & Stress Detection

This repository presents a comparative study of **Transformer models** applied to three key text classification tasks on social media content:

- ğŸ§¨ **Hate Speech Detection**
- ğŸ’¬ **Sentiment Analysis**
- ğŸ˜° **Stress/Anxiety Detection**

The dataset is derived from MonkeyPox-related social media posts and includes labeled examples for all three tasks.

---

## ğŸš€ Models Used

We fine-tuned and evaluated the following models for each classification task:

| Model                      | Parameters | Type                |
|---------------------------|------------|---------------------|
| `distilbert-base-uncased` | ~66M       | Lightweight BERT    |
| `bert-base-uncased`       | ~110M      | Standard BERT       |
| `roberta-base`            | ~125M      | Optimized BERT      |
| `microsoft/deberta-v3-small` | ~86M    | Disentangled BERT   |

All models were evaluated under identical conditions (same dataset splits, preprocessing steps, and training parameters).

---

## ğŸ§ª Tasks & Pipeline

Each model was fine-tuned separately for:

- **Hate classification** (e.g., `hate`, `not hate`)
- **Sentiment analysis** (e.g., `anger`, `disgust`, `fear`, `joy`, `neutral`, `sadness`, `surprise`)
- **Stress/anxiety detection** (e.g., `stress`, `no stress`)

All training scripts follow the same structure:

1. âœ… Data preprocessing and label encoding
2. âœ… Tokenization using Hugging Face tokenizer
3. âœ… Fine-tuning with Hugging Face `Trainer`
4. âœ… Evaluation using `F1`, `ROC AUC`, `Precision`, `Recall`
5. âœ… Automatic saving of best models and metric logs

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ data/
â”‚   â””â”€â”€ MonkeyPox.xlsx                     # Labeled dataset
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ distilbert_hate_final_model/
â”‚   â”œâ”€â”€ bert_sentiment_final_model/
â”‚   â”œâ”€â”€ roberta_stress_final_model/
â”‚   â””â”€â”€ deberta_hate_final_model/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_distilbert.py
â”‚   â”œâ”€â”€ train_bert.py
â”‚   â”œâ”€â”€ train_roberta.py
â”‚   â””â”€â”€ train_deberta.py
â”œâ”€â”€ results/
â”‚   â””â”€â”€ classification_metrics.csv         # All evaluation metrics
```

---

## ğŸ“Š Sample Evaluation Results

| Task      | Model                 | F1 Macro | ROC AUC | Best Epoch |
|-----------|------------------------|----------|---------|-------------|
| Hate      | DeBERTa-v3-small       | 0.94     | 0.96    | 3           |
| Sentiment | BERT Base              | 0.91     | 0.93    | 4           |
| Stress    | RoBERTa Base           | 0.89     | 0.92    | 5           |
| Hate      | DistilBERT             | 0.90     | 0.91    | 4           |

> ğŸ—‚ All metrics are automatically logged in `classification_metrics.csv`

---

## âš™ï¸ Installation

```bash
pip install -r requirements.txt
```

Or install dependencies manually:

```bash
pip install transformers datasets scikit-learn torch openpyxl
```

---

## ğŸ”® Future Work

- [ ] Cross-task transfer learning  
- [ ] Ensemble modeling for better generalization  
- [ ] Deployable web interface (Gradio / Streamlit)  
- [ ] Public dataset release and benchmark comparison  

---

## ğŸ‘¨â€ğŸ’» Author

Developed by **Emre Sebati Yolal**  
ğŸ“ MSc Candidate in Information Systems Engineering  
ğŸ’¡ Specializing in NLP, Deep Learning, and .NET backend development

---

## ğŸ§¾ License

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.
