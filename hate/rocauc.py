import pandas as pd
import torch
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, label_binarize
from sklearn.metrics import roc_auc_score, roc_curve
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from datasets import Dataset
import matplotlib.pyplot as plt
from torch.nn.functional import softmax

# ğŸ”Œ GPU kontrolÃ¼
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"KullanÄ±lan cihaz: {device}")

# ğŸ“Š Veriyi yÃ¼kle ve hazÄ±rla (TÃ¼m modeller iÃ§in bir kez)
def prepare_hate_data(path):
    df = pd.read_excel(path)
    df = df[['Translated Post Description', 'Hate']].dropna()
    df['Translated Post Description'] = df['Translated Post Description'].apply(lambda x: " ".join(str(x).split()[:250]))
    df['Hate'] = df['Hate'].str.lower().str.strip()

    le = LabelEncoder()
    df['label'] = le.fit_transform(df['Hate'])

    X_train, X_test, y_train, y_test = train_test_split(
        df['Translated Post Description'],
        df['label'],
        test_size=0.1,
        stratify=df['label'],
        random_state=42
    )
    return X_test, y_test, le

# ğŸ“‚ Veri dosyasÄ±
data_path = "../MonkeyPox.xlsx" 

# ğŸ“¥ Veriyi hazÄ±rla
X_test, y_test, le = prepare_hate_data(data_path)
num_labels = len(le.classes_) # SÄ±nÄ±f sayÄ±sÄ±nÄ± al

# KarÅŸÄ±laÅŸtÄ±rÄ±lacak modellerin listesi
# Model adlarÄ± ve kaydedildikleri yollar
models_to_compare = [
    {"name": "BERT", "path": "./bert_hate_final_model"},
    {"name": "DistilBERT", "path": "./distilbert_hate_final_model"},
    {"name": "DeBERTa-v3-small", "path": "./deberta_v3_small_hate_final_model"},
    {"name": "RoBERTa", "path": "./roberta_hate_final_model"}
]

plt.figure(figsize=(10, 8)) # Daha bÃ¼yÃ¼k bir grafik boyutu

# Her bir model iÃ§in ROC eÄŸrisini Ã§iz
for model_info in models_to_compare:
    model_name = model_info["name"]
    model_path = model_info["path"]
    
    print(f"\n--- {model_name} modelini yÃ¼klÃ¼yor ve tahminler yapÄ±yor... ---")
    try:
        model = AutoModelForSequenceClassification.from_pretrained(model_path)
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = model.to(device)
        model.eval() # Modeli deÄŸerlendirme moduna al
    except Exception as e:
        print(f"Hata: {model_name} modeli yÃ¼klenemedi veya bulunamadÄ±: {e}")
        print(f"LÃ¼tfen '{model_path}' yolunun doÄŸru olduÄŸundan ve modelin kaydedildiÄŸinden emin olun.")
        continue # Sonraki modele geÃ§

    # TOKENÄ°ZASYON (Her modelin kendi tokenizer'Ä± ile)
    test_ds = Dataset.from_dict({"text": X_test.tolist(), "label": y_test.tolist()})
    test_ds = test_ds.map(lambda x: tokenizer(x['text'], padding="max_length", truncation=True, max_length=512), batched=True)

    # MODEL Ä°LE TAHMÄ°N
    all_logits = []
    batch_size_inference = 8 # EÄŸitimdeki batch boyutunu kullanmak daha tutarlÄ± olabilir
    with torch.no_grad(): # Gradyan hesaplamalarÄ±nÄ± devre dÄ±ÅŸÄ± bÄ±rak
        for i in range(0, len(test_ds), batch_size_inference):
            batch = test_ds[i:i+batch_size_inference]
            inputs = {
                'input_ids': torch.tensor(batch['input_ids']).to(model.device),
                'attention_mask': torch.tensor(batch['attention_mask']).to(model.device)
            }
            outputs = model(**inputs)
            all_logits.append(outputs.logits.cpu().numpy())

    all_logits = np.concatenate(all_logits, axis=0)
    probs = softmax(torch.tensor(all_logits), dim=1).numpy()

    # ROC AUC ve EÄŸri Hesaplama
    if num_labels == 2:
        # Ä°kili sÄ±nÄ±flandÄ±rma (hate ve not hate) iÃ§in ROC AUC
        auc = roc_auc_score(y_test, probs[:, 1])
        fpr, tpr, _ = roc_curve(y_test, probs[:, 1])
        plt.plot(fpr, tpr, label=f"{model_name} (AUC = {auc:.4f})", linewidth=2)
    else:
        # Ã‡oklu sÄ±nÄ±flandÄ±rma iÃ§in ROC AUC (eÄŸer 2'den fazla sÄ±nÄ±f olsaydÄ±)
        y_test_binarized = label_binarize(y_test, classes=np.arange(num_labels))
        auc = roc_auc_score(y_test_binarized, probs, multi_class="ovo", average="macro")
        # Ã‡oklu sÄ±nÄ±flandÄ±rmada her sÄ±nÄ±f iÃ§in ayrÄ± ROC eÄŸrisi Ã§izmek yerine
        # basitleÅŸtirilmiÅŸ bir yaklaÅŸÄ±m veya belirli bir sÄ±nÄ±fÄ±n eÄŸrisi Ã§izilebilir.
        # Bu Ã¶rnekte, sadece genel AUC'yi gÃ¶sterip, tek bir eÄŸri Ã§iziyoruz (Ã¶rneÄŸin ilk sÄ±nÄ±f iÃ§in).
        # Daha detaylÄ± Ã§oklu sÄ±nÄ±f ROC iÃ§in ayrÄ± bir dÃ¶ngÃ¼ye ihtiyaÃ§ duyulur.
        print(f"UyarÄ±: Ã‡oklu sÄ±nÄ±flandÄ±rma iÃ§in tek bir ROC eÄŸrisi Ã§iziliyor. DetaylÄ± analiz iÃ§in her sÄ±nÄ±f iÃ§in ayrÄ± eÄŸri Ã§izilmesi gerekebilir.")
        fpr, tpr, _ = roc_curve(y_test_binarized[:, 0], probs[:, 0]) # Ä°lk sÄ±nÄ±fÄ±n eÄŸrisi
        plt.plot(fpr, tpr, label=f"{model_name} (Macro AUC = {auc:.4f})", linewidth=2)


# "Random Guess" (Rastgele Tahmin) Ã‡izgisi
plt.plot([0, 1], [0, 1], linestyle="--", color="gray", label="Random Guess", alpha=0.7)

plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Hate Classification - ROC Curve Comparison Across Models")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

print("\nâœ… TÃ¼m modeller iÃ§in ROC AUC eÄŸrileri baÅŸarÄ±yla Ã§izildi.")
